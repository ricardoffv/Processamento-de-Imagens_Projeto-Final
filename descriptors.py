'''
Authors
Lucas Yudi Sugi 							Numero USP: 9293251
Ricardo FranÃ§a Fernandes do Vale 	        Numero USP: 9293477
Discipline
SCC 0251 - Processamento de Imagens - 2018/1o sem - Prof. Moacir Ponti

Title
Processing the texture and gradient descriptors for an image
'''

import numpy as np 

'''
Returns the correlation of an image based on its coocurrence matrix
img: Original image from segmentation
G: Co-ocurrence matrix
unique: vector of color intensities present on the image 
'''
def coocurrence_correlation(G, unique):
	correlation = 0.0

	#Calculating mean and standard deviation values

	mean_i = mean_j = std_i = std_j = 0.0

	counter = 0
	for i in unique:
		mean_i = mean_i + (i*np.sum( G[counter, :] ))
		counter += 1

	counter = 0
	for j in unique:
		mean_j = mean_j + (j*np.sum( G[:, counter] ))
		counter += 1

	counter = 0
	for i in unique:
		std_i = std_i + (((i - mean_i)**2)*np.sum( G[counter, :] ))
		counter += 1

	counter = 0
	for i in unique:
		std_j = std_j + (((j - mean_j)**2)*np.sum( G[:, counter] ))
		counter += 1

	#Calculating correlation based on the values above
	if (std_i > 0 and std_j > 0):
		for i in range(G.shape[0]):
			for j in range(G.shape[1]):
				correlation = correlation + ((int(unique[i]) - mean_i)*(int(unique[j]) - mean_j))*G[i,j] 
		correlation = correlation/(std_i*std_j)

	return correlation	

'''
Extract the texture (Haralick) descriptors of the image
img: greyscale image
'''
def texture_descriptors(img):
	C = 256

	#Here it's setup the reverse mapping of the intensities of the image (to allow quick access) and the image intensities
	unique = np.unique(img)
	intensity = np.zeros(C, dtype=np.uint8)
	for key in range(len(unique)):
		intensity[unique[key]] = key

	#Creating the coocurrence matrix G, a sparse matrix that only will have as indexes intensities that exist in the image
	G = np.zeros([len(unique), len(unique)])

	#Setting G values
	for i in range(img.shape[0]-1):
		for j in range(img.shape[1]-1):
			G[ intensity[img[i,j]] ][ intensity[img[i+1,j+1]] ] += 1

	#normalizing G values
	G = G/np.sum(G)

	#Actual extraction of the Haralick Descriptors
	#Energy
	energy = np.sum(G**2)

	#Entropy
	entropy = - np.sum(G*(np.log(G+0.001)/np.log(2)))
	
	#Contrast
	contrast = 0.0
	for i in range(G.shape[0]):
		for j in range(G.shape[1]):
			contrast = contrast + float((int(unique[i])-int(unique[j]))**2)*G[i,j]
	contrast = contrast/((C-1)**2)

	#Correlation
	correlation = coocurrence_correlation(G, unique)

	#Homogeneity
	homogeneity = 0.0
	for i in range(G.shape[0]):
		for j in range(G.shape[1]):
			homogeneity = homogeneity + G[i,j]/(abs(int(unique[i])-int(unique[j]))+1)
	
	#Descriptors are returned as a single vector
	return np.array([energy, entropy, contrast, correlation, homogeneity])

'''
Applying an arbitrary filter on an image, returning the new value
weights: filter
x, y: pixel position
image: image that will apply itself convolution
'''
def abritary_filter (weights, x, y, image):
	n,m = weights.shape
	sub_matrix = np.zeros(weights.shape)

	a = int((n-1)/2)
	b = int((m-1)/2)
	row = 0
	for i in range(x-a,x+a+1):
		col = 0
		for j in range(y-b,y+b+1):
			if(i < image.shape[0] and i >= 0 and j < image.shape[0] and j >= 0):
				sub_matrix[row,col] = image[i,j]
			col += 1
		row += 1

	weights_flip = np.flip(np.flip(weights, 0) ,1)

	res = np.sum(np.multiply(sub_matrix, weights_flip))

	return res

'''
Applies space domain convolution
image: greyscale image
weights: filter used in the convolution
'''
def space_domain_convolution(image, weights):
	res = np.zeros(image.shape, dtype=float)
	for i in range(image.shape[0]):
		for j in range(image.shape[1]):
			res[i,j] = abritary_filter(weights, i, j, image)
	return res

'''
Operation of the Sobel filter on an image in the space domain
image: greyscale image
'''
def sobel_operation(image):
	#Setting filters
	fx = np.array([[1.0,0.0,-1.0],[2.0,0.0,-2.0],[1.0,0.0,-1.0]])
	fy = np.array([[1.0,2.0,1.0],[0.0,0.0,0.0],[-1.0,-2.0,-1.0]])

	#New images gx and gy generated by convolution
	gx = space_domain_convolution(image, fx) 
	gy = space_domain_convolution(image, fy) 
	
	return [gx, gy]

'''
Extract the histogram of Gradient (HOG), based on magnitude, of the image
img: greyscale image
'''
def gradient_descriptors(img):
	#Generating gx, gy
	[gx, gy] = sobel_operation(img)

	#Ignoring the edges of the image
	gx = gx[1:(gx.shape[0]-1), 1:(gx.shape[1]-1)]	
	gy = gy[1:(gy.shape[0]-1), 1:(gy.shape[1]-1)]	

	#Calculating magnitude
	M = np.sqrt((gx**2)+(gy**2))/np.sum(np.sqrt((gx**2)+(gy**2)))

	#Setting histogram, in which the 18 bins are divided by angles (in degreees) in an interval of 20 
	#and the value added to the bins, based on magnitude
	angles = (np.arctan2(gy, gx) * 180.0 / np.pi)+180.0
	histogram = np.zeros(18, dtype=float)
	for i in range(angles.shape[0]):
		for j in range(angles.shape[1]):
			if (angles[i,j] == 360):
				histogram[0] = histogram[0] + M[i,j]
			else:
				histogram[int(angles[i,j]/20)] = histogram[int(angles[i,j]/20)] + M[i,j]

	return histogram